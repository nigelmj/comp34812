{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11256979,"sourceType":"datasetVersion","datasetId":7035222},{"sourceId":318569,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":268818,"modelId":289844}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport random","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T15:47:36.657596Z","iopub.execute_input":"2025-04-03T15:47:36.658147Z","iopub.status.idle":"2025-04-03T15:47:40.119376Z","shell.execute_reply.started":"2025-04-03T15:47:36.658062Z","shell.execute_reply":"2025-04-03T15:47:40.118487Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T15:47:40.120471Z","iopub.execute_input":"2025-04-03T15:47:40.120968Z","iopub.status.idle":"2025-04-03T15:47:40.170512Z","shell.execute_reply.started":"2025-04-03T15:47:40.120938Z","shell.execute_reply":"2025-04-03T15:47:40.169593Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"MODEL_NAME = 'roberta-base'\nrandom.seed(a=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T15:47:40.172058Z","iopub.execute_input":"2025-04-03T15:47:40.172281Z","iopub.status.idle":"2025-04-03T15:47:40.185421Z","shell.execute_reply.started":"2025-04-03T15:47:40.172262Z","shell.execute_reply":"2025-04-03T15:47:40.184797Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from transformers import RobertaModel, AutoTokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T15:47:40.186592Z","iopub.execute_input":"2025-04-03T15:47:40.186854Z","iopub.status.idle":"2025-04-03T15:47:57.617325Z","shell.execute_reply.started":"2025-04-03T15:47:40.186833Z","shell.execute_reply":"2025-04-03T15:47:57.616443Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T15:47:57.618227Z","iopub.execute_input":"2025-04-03T15:47:57.618893Z","iopub.status.idle":"2025-04-03T15:48:02.536265Z","shell.execute_reply.started":"2025-04-03T15:47:57.618858Z","shell.execute_reply":"2025-04-03T15:48:02.535579Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"864b0c7de050406088e3f378334263d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae29582d61a4471b9b1e17b0e1554ff8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0d8e236b2234ed2ac7bde235e2a9630"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25bebf7f4eeb45e39f967c04cccc1160"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16e4236a37584e2b9a5b0be5c132656b"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"from torch.utils.data import DataLoader, Dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T15:48:02.536980Z","iopub.execute_input":"2025-04-03T15:48:02.537185Z","iopub.status.idle":"2025-04-03T15:48:02.540894Z","shell.execute_reply.started":"2025-04-03T15:48:02.537166Z","shell.execute_reply":"2025-04-03T15:48:02.540010Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class NLIDataset(Dataset):\n    def __init__(self, data):\n        self.encodings = tokenizer(list(data['premise']), list(data['hypothesis']), padding=True, truncation=True, return_tensors=\"pt\", max_length=MAX_LENGTH)\n\n    def __len__(self):\n        return self.encodings[\"input_ids\"].shape[0]\n\n    def __getitem__(self, idx):\n        item = {key: val[idx] for key, val in self.encodings.items()}\n        return item","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T15:48:02.541573Z","iopub.execute_input":"2025-04-03T15:48:02.541861Z","iopub.status.idle":"2025-04-03T15:48:02.597219Z","shell.execute_reply.started":"2025-04-03T15:48:02.541830Z","shell.execute_reply":"2025-04-03T15:48:02.596385Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class DNNTransformerModel(nn.Module):\n    def __init__(self, model_name, num_labels):\n        super(DNNTransformerModel, self).__init__()\n        self.transformer = RobertaModel.from_pretrained(model_name)\n        self.dnn = nn.Sequential(\n            nn.Linear(self.transformer.config.hidden_size, 512),\n            nn.LayerNorm(512),\n            nn.GELU(),\n            nn.Dropout(0.2),\n            nn.Linear(512, 256),\n            nn.LayerNorm(256),\n            nn.GELU(),\n            nn.Dropout(0.2),\n            nn.Linear(256, num_labels)\n        )\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.transformer(input_ids=input_ids, attention_mask=attention_mask)\n        hidden_state = outputs.last_hidden_state[:, 0, :]\n        logits = self.dnn(hidden_state)\n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T15:48:02.599527Z","iopub.execute_input":"2025-04-03T15:48:02.599793Z","iopub.status.idle":"2025-04-03T15:48:02.610013Z","shell.execute_reply.started":"2025-04-03T15:48:02.599760Z","shell.execute_reply":"2025-04-03T15:48:02.609186Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"modelPath = input(\"Input the path to the model with extension\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T15:48:02.611223Z","iopub.execute_input":"2025-04-03T15:48:02.611456Z","iopub.status.idle":"2025-04-03T15:48:04.924459Z","shell.execute_reply.started":"2025-04-03T15:48:02.611434Z","shell.execute_reply":"2025-04-03T15:48:04.923804Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Input the path to the model with extension /kaggle/input/nli_roberta_model/pytorch/default/1/nli_dnn_transformer.pth\n"}],"execution_count":9},{"cell_type":"code","source":"model = DNNTransformerModel(MODEL_NAME, num_labels=2)\nmodel.load_state_dict(torch.load(modelPath))\nmodel = model.to(DEVICE)\nmodel.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T15:48:04.925270Z","iopub.execute_input":"2025-04-03T15:48:04.925475Z","iopub.status.idle":"2025-04-03T15:48:12.531835Z","shell.execute_reply.started":"2025-04-03T15:48:04.925457Z","shell.execute_reply":"2025-04-03T15:48:12.530991Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6942d71397dd445ab94b2bafb2ccd7cd"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n<ipython-input-10-e344f96272d1>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(modelPath))\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"DNNTransformerModel(\n  (transformer): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): RobertaPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dnn): Sequential(\n    (0): Linear(in_features=768, out_features=512, bias=True)\n    (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (2): GELU(approximate='none')\n    (3): Dropout(p=0.2, inplace=False)\n    (4): Linear(in_features=512, out_features=256, bias=True)\n    (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n    (6): GELU(approximate='none')\n    (7): Dropout(p=0.2, inplace=False)\n    (8): Linear(in_features=256, out_features=2, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"documentPath = input(\"Input the path to the document\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T15:48:12.532632Z","iopub.execute_input":"2025-04-03T15:48:12.532957Z","iopub.status.idle":"2025-04-03T15:48:16.599025Z","shell.execute_reply.started":"2025-04-03T15:48:12.532927Z","shell.execute_reply":"2025-04-03T15:48:16.598344Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Input the path to the document /kaggle/input/testss/test.csv\n"}],"execution_count":11},{"cell_type":"code","source":"import pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T15:49:31.638308Z","iopub.execute_input":"2025-04-03T15:49:31.638648Z","iopub.status.idle":"2025-04-03T15:49:31.642427Z","shell.execute_reply.started":"2025-04-03T15:49:31.638618Z","shell.execute_reply":"2025-04-03T15:49:31.641591Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"document = pd.read_csv(documentPath)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T15:49:31.643453Z","iopub.execute_input":"2025-04-03T15:49:31.643747Z","iopub.status.idle":"2025-04-03T15:49:31.682174Z","shell.execute_reply.started":"2025-04-03T15:49:31.643698Z","shell.execute_reply":"2025-04-03T15:49:31.681505Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"BATCH_SIZE = 16\nMAX_LENGTH = 256","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T15:50:05.216302Z","iopub.execute_input":"2025-04-03T15:50:05.216616Z","iopub.status.idle":"2025-04-03T15:50:05.220319Z","shell.execute_reply.started":"2025-04-03T15:50:05.216589Z","shell.execute_reply":"2025-04-03T15:50:05.219347Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"doc_dataset = NLIDataset(document)\ndoc_loader = DataLoader(doc_dataset, batch_size=BATCH_SIZE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T15:50:05.221369Z","iopub.execute_input":"2025-04-03T15:50:05.221575Z","iopub.status.idle":"2025-04-03T15:50:05.503879Z","shell.execute_reply.started":"2025-04-03T15:50:05.221557Z","shell.execute_reply":"2025-04-03T15:50:05.502959Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"predictions = []\nwith torch.no_grad():\n    for batch in doc_loader:\n        input_ids = batch['input_ids'].to(DEVICE)\n        attention_mask = batch['attention_mask'].to(DEVICE)\n        \n        logits = model(input_ids, attention_mask)\n        predictions.extend(torch.argmax(logits, dim=1).cpu().numpy())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T15:50:18.245565Z","iopub.execute_input":"2025-04-03T15:50:18.245889Z","iopub.status.idle":"2025-04-03T15:50:26.257400Z","shell.execute_reply.started":"2025-04-03T15:50:18.245864Z","shell.execute_reply":"2025-04-03T15:50:26.256685Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"results_df = pd.DataFrame({'predictions': predictions})\nresults_df.to_csv('output.csv.predict', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T15:50:26.258669Z","iopub.execute_input":"2025-04-03T15:50:26.259006Z","iopub.status.idle":"2025-04-03T15:50:26.275430Z","shell.execute_reply.started":"2025-04-03T15:50:26.258976Z","shell.execute_reply":"2025-04-03T15:50:26.274808Z"}},"outputs":[],"execution_count":21}]}