{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11272722,"sourceType":"datasetVersion","datasetId":7046880},{"sourceId":320428,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":270265,"modelId":291253}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport random","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-04T08:51:50.171944Z","iopub.execute_input":"2025-04-04T08:51:50.172246Z","iopub.status.idle":"2025-04-04T08:51:53.735977Z","shell.execute_reply.started":"2025-04-04T08:51:50.172212Z","shell.execute_reply":"2025-04-04T08:51:53.734928Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T08:51:53.737088Z","iopub.execute_input":"2025-04-04T08:51:53.737513Z","iopub.status.idle":"2025-04-04T08:51:53.817244Z","shell.execute_reply.started":"2025-04-04T08:51:53.737461Z","shell.execute_reply":"2025-04-04T08:51:53.816069Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"MODEL_NAME = 'roberta-base'\nrandom.seed(a=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T08:51:53.818231Z","iopub.execute_input":"2025-04-04T08:51:53.818570Z","iopub.status.idle":"2025-04-04T08:51:53.838884Z","shell.execute_reply.started":"2025-04-04T08:51:53.818537Z","shell.execute_reply":"2025-04-04T08:51:53.837696Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from transformers import RobertaModel, AutoTokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T08:51:53.839910Z","iopub.execute_input":"2025-04-04T08:51:53.840224Z","iopub.status.idle":"2025-04-04T08:52:13.021657Z","shell.execute_reply.started":"2025-04-04T08:51:53.840193Z","shell.execute_reply":"2025-04-04T08:52:13.020687Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T08:52:13.022669Z","iopub.execute_input":"2025-04-04T08:52:13.023211Z","iopub.status.idle":"2025-04-04T08:52:14.465941Z","shell.execute_reply.started":"2025-04-04T08:52:13.023186Z","shell.execute_reply":"2025-04-04T08:52:14.465019Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c36549266b0040fa8e6008b4393bbe71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d8f6fdf9fa84115bd0c51263d449ccc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47a0a3a9aeeb40e7b7223e7aaebbbb5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"685af11ff38044bbb0d54fb921b028a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f891602b11064d95b3ec597161418545"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"from torch.utils.data import DataLoader, Dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T08:52:14.468904Z","iopub.execute_input":"2025-04-04T08:52:14.469166Z","iopub.status.idle":"2025-04-04T08:52:14.473126Z","shell.execute_reply.started":"2025-04-04T08:52:14.469144Z","shell.execute_reply":"2025-04-04T08:52:14.472055Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class NLIDataset(Dataset):\n    def __init__(self, data):\n        self.encodings = tokenizer(list(data['premise']), list(data['hypothesis']), padding=True, truncation=True, return_tensors=\"pt\", max_length=MAX_LENGTH)\n        self.labels = torch.tensor(data['label'].values, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self,idx):\n        item = {key: val[idx] for key, val in self.encodings.items()}\n        item['labels'] = self.labels[idx]\n        return item","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T08:52:14.474836Z","iopub.execute_input":"2025-04-04T08:52:14.475198Z","iopub.status.idle":"2025-04-04T08:52:14.491148Z","shell.execute_reply.started":"2025-04-04T08:52:14.475168Z","shell.execute_reply":"2025-04-04T08:52:14.490268Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class DNNTransformerModel(nn.Module):\n    def __init__(self, model_name, num_labels):\n        super(DNNTransformerModel, self).__init__()\n        self.transformer = RobertaModel.from_pretrained(model_name)\n        self.dnn = nn.Sequential(\n            nn.Linear(self.transformer.config.hidden_size, 512),\n            nn.LayerNorm(512),\n            nn.GELU(),\n            nn.Dropout(0.2),\n            nn.Linear(512, 256),\n            nn.LayerNorm(256),\n            nn.GELU(),\n            nn.Dropout(0.2),\n            nn.Linear(256, num_labels)\n        )\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.transformer(input_ids=input_ids, attention_mask=attention_mask)\n        hidden_state = outputs.last_hidden_state[:, 0, :]\n        logits = self.dnn(hidden_state)\n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T08:52:14.491965Z","iopub.execute_input":"2025-04-04T08:52:14.492218Z","iopub.status.idle":"2025-04-04T08:52:14.507605Z","shell.execute_reply.started":"2025-04-04T08:52:14.492198Z","shell.execute_reply":"2025-04-04T08:52:14.506775Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"modelPath = \"/kaggle/input/nli_c/pytorch/default/1/nli_dnn_transformer.pth\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T08:52:14.508641Z","iopub.execute_input":"2025-04-04T08:52:14.508906Z","iopub.status.idle":"2025-04-04T08:52:14.524144Z","shell.execute_reply.started":"2025-04-04T08:52:14.508884Z","shell.execute_reply":"2025-04-04T08:52:14.523429Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"model = DNNTransformerModel(MODEL_NAME, num_labels=2)\nmodel.load_state_dict(torch.load(modelPath))\nmodel = model.to(DEVICE)\nmodel.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T08:52:14.525124Z","iopub.execute_input":"2025-04-04T08:52:14.525438Z","iopub.status.idle":"2025-04-04T08:52:22.102829Z","shell.execute_reply.started":"2025-04-04T08:52:14.525408Z","shell.execute_reply":"2025-04-04T08:52:22.102020Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfad5148b8454675b1da7b79f165a0f5"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n<ipython-input-10-e344f96272d1>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(modelPath))\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"DNNTransformerModel(\n  (transformer): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): RobertaPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dnn): Sequential(\n    (0): Linear(in_features=768, out_features=512, bias=True)\n    (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (2): GELU(approximate='none')\n    (3): Dropout(p=0.2, inplace=False)\n    (4): Linear(in_features=512, out_features=256, bias=True)\n    (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n    (6): GELU(approximate='none')\n    (7): Dropout(p=0.2, inplace=False)\n    (8): Linear(in_features=256, out_features=2, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"documentPath = input(\"Input the path to the document\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T08:52:22.103719Z","iopub.execute_input":"2025-04-04T08:52:22.104079Z","iopub.status.idle":"2025-04-04T08:52:28.051798Z","shell.execute_reply.started":"2025-04-04T08:52:22.104043Z","shell.execute_reply":"2025-04-04T08:52:28.051059Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Input the path to the document /kaggle/input/testing-data/dev.csv\n"}],"execution_count":11},{"cell_type":"code","source":"import pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T08:52:28.052553Z","iopub.execute_input":"2025-04-04T08:52:28.052815Z","iopub.status.idle":"2025-04-04T08:52:28.057110Z","shell.execute_reply.started":"2025-04-04T08:52:28.052793Z","shell.execute_reply":"2025-04-04T08:52:28.055795Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"document = pd.read_csv(documentPath)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T08:52:28.058357Z","iopub.execute_input":"2025-04-04T08:52:28.058699Z","iopub.status.idle":"2025-04-04T08:52:30.099523Z","shell.execute_reply.started":"2025-04-04T08:52:28.058665Z","shell.execute_reply":"2025-04-04T08:52:30.098688Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"BATCH_SIZE = 16\nMAX_LENGTH = 256","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T08:52:30.100291Z","iopub.execute_input":"2025-04-04T08:52:30.100563Z","iopub.status.idle":"2025-04-04T08:52:30.104607Z","shell.execute_reply.started":"2025-04-04T08:52:30.100541Z","shell.execute_reply":"2025-04-04T08:52:30.103473Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"doc_dataset = NLIDataset(document)\ndoc_loader = DataLoader(doc_dataset, batch_size=BATCH_SIZE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T08:52:30.105549Z","iopub.execute_input":"2025-04-04T08:52:30.105807Z","iopub.status.idle":"2025-04-04T08:52:31.092952Z","shell.execute_reply.started":"2025-04-04T08:52:30.105784Z","shell.execute_reply":"2025-04-04T08:52:31.092163Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T08:53:01.152704Z","iopub.execute_input":"2025-04-04T08:53:01.153062Z","iopub.status.idle":"2025-04-04T08:53:01.157378Z","shell.execute_reply.started":"2025-04-04T08:53:01.153034Z","shell.execute_reply":"2025-04-04T08:53:01.156224Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"predictions, true_labels = [], []\n\nwith torch.no_grad():\n    for batch in tqdm(doc_loader):\n        input_ids = batch['input_ids'].to(DEVICE)\n        attention_mask = batch['attention_mask'].to(DEVICE)\n        labels = batch['labels'].to(DEVICE)\n\n        logits = model(input_ids, attention_mask)\n    \n        predictions.extend(torch.argmax(logits, dim=1).cpu().numpy())\n        true_labels.extend(labels.cpu().numpy())\n\nprint(\"Classification Report:\")\nprint(classification_report(true_labels, predictions))\n\nprint(\"\\nConfusion Matrix:\")\nprint(confusion_matrix(true_labels, predictions))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T08:54:19.085098Z","iopub.execute_input":"2025-04-04T08:54:19.085536Z","iopub.status.idle":"2025-04-04T08:54:49.887621Z","shell.execute_reply.started":"2025-04-04T08:54:19.085507Z","shell.execute_reply":"2025-04-04T08:54:49.886684Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 421/421 [00:30<00:00, 13.68it/s]","output_type":"stream"},{"name":"stdout","text":"Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.86      0.86      0.86      3258\n           1       0.86      0.87      0.87      3478\n\n    accuracy                           0.86      6736\n   macro avg       0.86      0.86      0.86      6736\nweighted avg       0.86      0.86      0.86      6736\n\n\nConfusion Matrix:\n[[2786  472]\n [ 460 3018]]\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"results_df = pd.DataFrame({'predictions': predictions})\nresults_df.to_csv('results.csv.predict', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T08:55:02.802092Z","iopub.execute_input":"2025-04-04T08:55:02.802421Z","iopub.status.idle":"2025-04-04T08:55:02.824087Z","shell.execute_reply.started":"2025-04-04T08:55:02.802397Z","shell.execute_reply":"2025-04-04T08:55:02.823239Z"}},"outputs":[],"execution_count":23}]}