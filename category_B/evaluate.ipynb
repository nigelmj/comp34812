{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Inference\n",
    "### Using an ensemble Architecture with Attention and Local Inference Modelling\n",
    "\n",
    "This notebook evaluates the performance of the model on a validation set.\n",
    "Hyperparameters are set to the same values as they are in the training pipeline.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T09:23:06.329118Z",
     "iopub.status.busy": "2025-04-04T09:23:06.328806Z",
     "iopub.status.idle": "2025-04-04T09:23:06.332818Z",
     "shell.execute_reply": "2025-04-04T09:23:06.331929Z",
     "shell.execute_reply.started": "2025-04-04T09:23:06.329092Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T09:23:06.334237Z",
     "iopub.status.busy": "2025-04-04T09:23:06.333982Z",
     "iopub.status.idle": "2025-04-04T09:23:06.349094Z",
     "shell.execute_reply": "2025-04-04T09:23:06.348260Z",
     "shell.execute_reply.started": "2025-04-04T09:23:06.334217Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the hyperparameters that were selected for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T09:23:06.350968Z",
     "iopub.status.busy": "2025-04-04T09:23:06.350740Z",
     "iopub.status.idle": "2025-04-04T09:23:06.361652Z",
     "shell.execute_reply": "2025-04-04T09:23:06.360909Z",
     "shell.execute_reply.started": "2025-04-04T09:23:06.350949Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 20000\n",
    "MAX_LENGTH = 35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reads the specificied csv file and splits into required columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T09:23:06.363069Z",
     "iopub.status.busy": "2025-04-04T09:23:06.362836Z",
     "iopub.status.idle": "2025-04-04T09:23:06.374266Z",
     "shell.execute_reply": "2025-04-04T09:23:06.373404Z",
     "shell.execute_reply.started": "2025-04-04T09:23:06.363051Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_data(csv_path):\n",
    "    \"\"\"Load dataset from CSV file\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    return df[\"premise\"].astype(str).tolist(), df[\"hypothesis\"].astype(str).tolist(), df[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T09:23:06.375460Z",
     "iopub.status.busy": "2025-04-04T09:23:06.375134Z",
     "iopub.status.idle": "2025-04-04T09:23:14.697396Z",
     "shell.execute_reply": "2025-04-04T09:23:14.696684Z",
     "shell.execute_reply.started": "2025-04-04T09:23:06.375429Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input the path to validation data:  /kaggle/input/nlu-dataset/dev.csv\n"
     ]
    }
   ],
   "source": [
    "val_data_path = input(\"Input the path to validation data: \")\n",
    "val_premises, val_hypotheses, val_labels = load_data(val_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the tokeniser that was created during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T09:23:14.698514Z",
     "iopub.status.busy": "2025-04-04T09:23:14.698197Z",
     "iopub.status.idle": "2025-04-04T09:23:20.998390Z",
     "shell.execute_reply": "2025-04-04T09:23:20.997645Z",
     "shell.execute_reply.started": "2025-04-04T09:23:14.698485Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input the path to tokenizer:  /kaggle/input/testing/tokenizer.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "tokenizer = input(\"Input the path to tokenizer: \")\n",
    "with open(tokenizer, \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Tokenise the input sequences and pad them to the maximum length.\n",
    "Change the labels into 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T09:23:20.999517Z",
     "iopub.status.busy": "2025-04-04T09:23:20.999205Z",
     "iopub.status.idle": "2025-04-04T09:23:21.003875Z",
     "shell.execute_reply": "2025-04-04T09:23:21.002911Z",
     "shell.execute_reply.started": "2025-04-04T09:23:20.999487Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def tokenize_and_pad(texts, tokenizer, max_length):\n",
    "    \"\"\"Convert text to sequences and pad\"\"\"\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    return pad_sequences(sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T09:23:21.005032Z",
     "iopub.status.busy": "2025-04-04T09:23:21.004755Z",
     "iopub.status.idle": "2025-04-04T09:23:21.227229Z",
     "shell.execute_reply": "2025-04-04T09:23:21.226478Z",
     "shell.execute_reply.started": "2025-04-04T09:23:21.005004Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_val_p = tokenize_and_pad(val_premises, tokenizer, MAX_LENGTH)\n",
    "X_val_h = tokenize_and_pad(val_hypotheses, tokenizer, MAX_LENGTH)\n",
    "y_val = to_categorical(val_labels, num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to use the GloVe 6B, 300 dimensional embeddings file for the pretrained embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T09:23:21.230088Z",
     "iopub.status.busy": "2025-04-04T09:23:21.229879Z",
     "iopub.status.idle": "2025-04-04T09:23:21.233342Z",
     "shell.execute_reply": "2025-04-04T09:23:21.232475Z",
     "shell.execute_reply.started": "2025-04-04T09:23:21.230070Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T09:23:21.234466Z",
     "iopub.status.busy": "2025-04-04T09:23:21.234238Z",
     "iopub.status.idle": "2025-04-04T09:23:21.248250Z",
     "shell.execute_reply": "2025-04-04T09:23:21.247235Z",
     "shell.execute_reply.started": "2025-04-04T09:23:21.234447Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_glove_embeddings(glove_file):\n",
    "    \"\"\"\n",
    "    Load the embeddings for every word in the file\n",
    "    \"\"\"\n",
    "    embeddings_index = {}\n",
    "    with open(glove_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T09:23:21.249367Z",
     "iopub.status.busy": "2025-04-04T09:23:21.249087Z",
     "iopub.status.idle": "2025-04-04T09:23:56.236575Z",
     "shell.execute_reply": "2025-04-04T09:23:56.235805Z",
     "shell.execute_reply.started": "2025-04-04T09:23:21.249346Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input the path to glove embeddings file:  /kaggle/input/glove300/glove.6B.300d.txt\n"
     ]
    }
   ],
   "source": [
    "glove_path = input(\"Input the path to glove embeddings file: \")\n",
    "embeddings_index = load_glove_embeddings(glove_path, EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to training, create the embedding matrix for every word in the tokeniser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T09:23:56.237675Z",
     "iopub.status.busy": "2025-04-04T09:23:56.237362Z",
     "iopub.status.idle": "2025-04-04T09:23:56.242146Z",
     "shell.execute_reply": "2025-04-04T09:23:56.241254Z",
     "shell.execute_reply.started": "2025-04-04T09:23:56.237635Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_embedding_matrix(embedding_index, word_index, embedding_dim, vocab_size):\n",
    "    \"\"\"\n",
    "    Creates an embedding matrix from the GloVe embeddings.\n",
    "    \"\"\"\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "    \n",
    "    for word, index in word_index.items():\n",
    "        if index >= vocab_size:\n",
    "            break\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector\n",
    "    \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T09:23:56.243389Z",
     "iopub.status.busy": "2025-04-04T09:23:56.243068Z",
     "iopub.status.idle": "2025-04-04T09:23:56.326938Z",
     "shell.execute_reply": "2025-04-04T09:23:56.326260Z",
     "shell.execute_reply.started": "2025-04-04T09:23:56.243360Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "embedding_matrix = create_embedding_matrix(embeddings_index, word_index, EMBEDDING_DIM, VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify custom functions used in the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T09:23:56.327890Z",
     "iopub.status.busy": "2025-04-04T09:23:56.327692Z",
     "iopub.status.idle": "2025-04-04T09:23:56.332099Z",
     "shell.execute_reply": "2025-04-04T09:23:56.331419Z",
     "shell.execute_reply.started": "2025-04-04T09:23:56.327874Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def soft_attention(premise, hypothesis):\n",
    "    attention = Dot(axes=-1)([premise, hypothesis])\n",
    "    premise_attn = Softmax(axis=-1)(attention)\n",
    "    hypothesis_attn = Softmax(axis=-2)(attention)\n",
    "\n",
    "    premise_aligned = Dot(axes=1)([premise_attn, hypothesis])\n",
    "    hypothesis_aligned = Dot(axes=1)([hypothesis_attn, premise])\n",
    "    return premise_aligned, hypothesis_aligned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify paths to models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T09:23:56.333042Z",
     "iopub.status.busy": "2025-04-04T09:23:56.332844Z",
     "iopub.status.idle": "2025-04-04T09:24:20.212777Z",
     "shell.execute_reply": "2025-04-04T09:24:20.211909Z",
     "shell.execute_reply.started": "2025-04-04T09:23:56.333024Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input the path to LSTM model:  /kaggle/input/ensemble/tensorflow2/default/1/nli_LSTM_model.keras\n",
      "Input the path to BiLSTM model:  /kaggle/input/ensemble/tensorflow2/default/1/nli_BiLSTM_model.keras\n",
      "Input the path to GRU model:  /kaggle/input/ensemble/tensorflow2/default/1/nli_GRU_model.keras\n",
      "Input the path to BiGRU model:  /kaggle/input/ensemble/tensorflow2/default/1/nli_BiGRU_model.keras\n"
     ]
    }
   ],
   "source": [
    "lstm_path = input(\"Input the path to LSTM model: \")\n",
    "bilstm_path = input(\"Input the path to BiLSTM model: \")\n",
    "gru_path = input(\"Input the path to GRU model: \")\n",
    "bigru_path = input(\"Input the path to BiGRU model: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T09:24:20.214014Z",
     "iopub.status.busy": "2025-04-04T09:24:20.213703Z",
     "iopub.status.idle": "2025-04-04T09:24:20.220039Z",
     "shell.execute_reply": "2025-04-04T09:24:20.219238Z",
     "shell.execute_reply.started": "2025-04-04T09:24:20.213983Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T09:24:20.221337Z",
     "iopub.status.busy": "2025-04-04T09:24:20.220995Z",
     "iopub.status.idle": "2025-04-04T09:24:25.310864Z",
     "shell.execute_reply": "2025-04-04T09:24:25.310149Z",
     "shell.execute_reply.started": "2025-04-04T09:24:20.221303Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"LSTM\": load_model(\n",
    "        lstm_path,\n",
    "        custom_objects={\"soft_attention\": soft_attention}\n",
    "    ),\n",
    "    \"BiLSTM\": load_model(\n",
    "        bilstm_path,\n",
    "        custom_objects={\"soft_attention\": soft_attention}\n",
    "    ),\n",
    "    \"GRU\": load_model(\n",
    "        gru_path,\n",
    "        custom_objects={\"soft_attention\": soft_attention}\n",
    "    ),\n",
    "    \"BiGRU\": load_model(\n",
    "        bigru_path,\n",
    "        custom_objects={\"soft_attention\": soft_attention}\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the saved model weights for weighted averaging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T09:24:25.311919Z",
     "iopub.status.busy": "2025-04-04T09:24:25.311691Z",
     "iopub.status.idle": "2025-04-04T09:24:37.946396Z",
     "shell.execute_reply": "2025-04-04T09:24:37.945653Z",
     "shell.execute_reply.started": "2025-04-04T09:24:25.311898Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input the path to model accuracy weights:  /kaggle/input/ensemble-model-weights/model_accuracy_weights.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "weights_path = input(\"Input the path to model accuracy weights: \")\n",
    "with open(weights_path, \"r\") as f:\n",
    "    weights = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T09:24:37.947476Z",
     "iopub.status.busy": "2025-04-04T09:24:37.947259Z",
     "iopub.status.idle": "2025-04-04T09:24:49.706214Z",
     "shell.execute_reply": "2025-04-04T09:24:49.705440Z",
     "shell.execute_reply.started": "2025-04-04T09:24:37.947459Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step\n"
     ]
    }
   ],
   "source": [
    "weighted_sum = np.zeros((X_val_p.shape[0], 2), dtype=np.float32)\n",
    "    \n",
    "for name, model in models.items():\n",
    "    raw_preds = model.predict([X_val_p, X_val_h])\n",
    "\n",
    "    # Apply weighting and accumulate\n",
    "    weighted_preds = raw_preds * weights[name]\n",
    "    weighted_sum += weighted_preds\n",
    "\n",
    "# Calculate final predictions\n",
    "y_pred = np.argmax(weighted_sum, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance of the model using Accuracy, Precision, Recall, and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T09:24:49.707362Z",
     "iopub.status.busy": "2025-04-04T09:24:49.707052Z",
     "iopub.status.idle": "2025-04-04T09:24:50.098472Z",
     "shell.execute_reply": "2025-04-04T09:24:50.097715Z",
     "shell.execute_reply.started": "2025-04-04T09:24:49.707328Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7185    0.6636    0.6900      3258\n",
      "           1     0.7059    0.7565    0.7303      3478\n",
      "\n",
      "    accuracy                         0.7115      6736\n",
      "   macro avg     0.7122    0.7100    0.7101      6736\n",
      "weighted avg     0.7120    0.7115    0.7108      6736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(val_labels, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the predictions to format specified by CodaBench."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T09:24:50.100072Z",
     "iopub.status.busy": "2025-04-04T09:24:50.099303Z",
     "iopub.status.idle": "2025-04-04T09:24:50.104061Z",
     "shell.execute_reply": "2025-04-04T09:24:50.103142Z",
     "shell.execute_reply.started": "2025-04-04T09:24:50.100040Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def save_predictions_only(y_pred, output_path):\n",
    "    \"\"\"Save only the predictions to a CSV file with a 'predictions' column.\"\"\"\n",
    "    df = pd.DataFrame({\"predictions\": y_pred.flatten()})\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Predictions saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T09:24:50.105187Z",
     "iopub.status.busy": "2025-04-04T09:24:50.104905Z",
     "iopub.status.idle": "2025-04-04T09:24:50.359013Z",
     "shell.execute_reply": "2025-04-04T09:24:50.358121Z",
     "shell.execute_reply.started": "2025-04-04T09:24:50.105150Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to Group_47_B_evaluation.csv.predict\n"
     ]
    }
   ],
   "source": [
    "save_predictions_only(y_pred, \"Group_47_B_evaluation.csv.predict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: Group_47_B_evaluation.csv.predict (deflated 90%)\n"
     ]
    }
   ],
   "source": [
    "!zip \"nli_ensemble_attention.zip\" \"Group_47_B_evaluation.csv.predict\""
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7023853,
     "sourceId": 11241996,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7032281,
     "sourceId": 11253160,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7043910,
     "sourceId": 11268612,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7044164,
     "sourceId": 11269004,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 290889,
     "modelInstanceId": 269898,
     "sourceId": 319900,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
